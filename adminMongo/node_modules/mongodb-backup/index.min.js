"use strict";

function error(err) {
    err && logger(err.message);
}

function writeMetadata(collection, metadata, next) {
    return collection.indexes(function(err, indexes) {
        return err ? next(err) : void fs.writeFile(metadata + collection.collectionName, JSON.stringify(indexes), next);
    });
}

function makeDir(pathname, next) {
    fs.stat(pathname, function(err, stats) {
        return err && "ENOENT" === err.code ? (logger("make dir at " + pathname), fs.mkdir(pathname, function(err) {
            next(err, pathname);
        })) : stats && stats.isDirectory() === !1 ? (logger("unlink file at " + pathname), 
        fs.unlink(pathname, function(err) {
            return err ? next(err) : (logger("make dir at " + pathname), void fs.mkdir(pathname, function(err) {
                next(err, pathname);
            }));
        })) : void next(null, pathname);
    });
}

function rmDir(pathname, next) {
    fs.readdirSync(pathname).forEach(function(first) {
        var database = pathname + first;
        if (fs.statSync(database).isDirectory() === !1) return next(Error("path is not a Directory"));
        var metadata = "", collections = fs.readdirSync(database), metadataPath = path.join(database, ".metadata");
        return fs.existsSync(metadataPath) === !0 && (metadata = metadataPath + path.sep, 
        delete collections[collections.indexOf(".metadata")]), collections.forEach(function(second) {
            var collection = path.join(database, second);
            fs.statSync(collection).isDirectory() !== !1 && (fs.readdirSync(collection).forEach(function(third) {
                var document = path.join(collection, third);
                return fs.unlinkSync(document), next ? next(null, document) : "";
            }), "" !== metadata && fs.unlinkSync(metadata + second), fs.rmdirSync(collection));
        }), "" !== metadata && fs.rmdirSync(metadata), fs.rmdirSync(database);
    });
}

function toJsonAsync(doc, collectionPath) {
    fs.writeFile(collectionPath + doc._id + ".json", JSON.stringify(doc));
}

function toBsonAsync(doc, collectionPath) {
    fs.writeFile(collectionPath + doc._id + ".bson", BSON.serialize(doc));
}

function allCollections(db, name, query, metadata, parser, next) {
    return db.collections(function(err, collections) {
        if (err) return next(err);
        var last = ~~collections.length, index = 0;
        return 0 === last ? next(err) : void collections.forEach(function(collection) {
            return systemRegex.test(collection.collectionName) === !0 ? last === ++index ? next(null) : null : (logger("select collection " + collection.collectionName), 
            void makeDir(name + collection.collectionName + path.sep, function(err, name) {
                return err ? last === ++index ? next(err) : error(err) : void meta(collection, metadata, function() {
                    var stream = collection.find(query).snapshot(!0).stream();
                    stream.once("end", function() {
                        return last === ++index ? next(null) : null;
                    }).on("data", function(doc) {
                        parser(doc, name);
                    });
                });
            }));
        });
    });
}

function allCollectionsScan(db, name, numCursors, metadata, parser, next) {
    return db.collections(function(err, collections) {
        if (err) return next(err);
        var last = ~~collections.length, index = 0;
        return 0 === last ? next(null) : void collections.forEach(function(collection) {
            return systemRegex.test(collection.collectionName) === !0 ? last === ++index ? next(null) : null : (logger("select collection scan " + collection.collectionName), 
            void makeDir(name + collection.collectionName + path.sep, function(err, name) {
                return err ? last === ++index ? next(err) : error(err) : void meta(collection, metadata, function() {
                    collection.parallelCollectionScan({
                        numCursors: numCursors
                    }, function(err, cursors) {
                        if (err) return last === ++index ? next(err) : error(err);
                        var ii, cursorsDone;
                        if (ii = cursorsDone = ~~cursors.length, 0 === ii) return last === ++index ? next(null) : null;
                        for (var i = 0; i < ii; ++i) cursors[i].once("end", function() {
                            if (0 === --cursorsDone) return last === ++index ? next(null) : null;
                        }).on("data", function(doc) {
                            parser(doc, name);
                        });
                    });
                });
            }));
        });
    });
}

function someCollections(db, name, query, metadata, parser, next, collections) {
    var last = ~~collections.length, index = 0;
    return 0 === last ? next(null) : void collections.forEach(function(collection) {
        db.collection(collection, {
            strict: !0
        }, function(err, collection) {
            return err ? last === ++index ? next(err) : error(err) : (logger("select collection " + collection.collectionName), 
            void makeDir(name + collection.collectionName + path.sep, function(err, name) {
                return err ? last === ++index ? next(err) : error(err) : void meta(collection, metadata, function() {
                    var stream = collection.find(query).snapshot(!0).stream();
                    stream.once("end", function() {
                        return last === ++index ? next(null) : null;
                    }).on("data", function(doc) {
                        parser(doc, name);
                    });
                });
            }));
        });
    });
}

function someCollectionsScan(db, name, numCursors, metadata, parser, next, collections) {
    var last = ~~collections.length, index = 0;
    return 0 === last ? next(null) : void collections.forEach(function(collection) {
        db.collection(collection, {
            strict: !0
        }, function(err, collection) {
            return err ? last === ++index ? next(err) : error(err) : (logger("select collection scan " + collection.collectionName), 
            void makeDir(name + collection.collectionName + path.sep, function(err, name) {
                return err ? last === ++index ? next(err) : error(err) : void meta(collection, metadata, function() {
                    collection.parallelCollectionScan({
                        numCursors: numCursors
                    }, function(err, cursors) {
                        if (err) return last === ++index ? next(err) : error(err);
                        var ii, cursorsDone;
                        if (ii = cursorsDone = ~~cursors.length, 0 === ii) return last === ++index ? next(null) : null;
                        for (var i = 0; i < ii; ++i) cursors[i].once("end", function() {
                            if (0 === --cursorsDone) return last === ++index ? next(null) : null;
                        }).on("data", function(doc) {
                            parser(doc, name);
                        });
                    });
                });
            }));
        });
    });
}

function wrapper(my) {
    function callback(err) {
        logger("backup stop"), null !== my.callback ? (logger("callback run"), my.callback(err)) : err && logger(err);
    }
    var parser;
    if ("function" == typeof my.parser) parser = my.parser; else switch (my.parser.toLowerCase()) {
      case "bson":
        BSON = require("bson"), BSON = new BSON(), parser = toBsonAsync;
        break;

      case "json":
        parser = toJsonAsync;
        break;

      default:
        throw new Error("missing parser option");
    }
    var discriminator = allCollections;
    if (null !== my.collections ? (discriminator = someCollections, my.numCursors && (discriminator = someCollectionsScan, 
    my.query = my.numCursors)) : my.numCursors && (discriminator = allCollectionsScan, 
    my.query = my.numCursors), null === my.logger) logger = function() {}; else {
        logger = require("logger-request")({
            filename: my.logger,
            standalone: !0,
            daily: !0,
            winston: {
                logger: "_mongo_b" + my.logger,
                level: "info",
                json: !1
            }
        }), logger("backup start");
        var log = require("mongodb").Logger;
        log.setLevel("info"), log.setCurrentLogger(function(msg) {
            return logger(msg);
        });
    }
    var metadata = "";
    meta = my.metadata === !0 ? writeMetadata : function(a, b, c) {
        return c();
    }, require("mongodb").MongoClient.connect(my.uri, my.options, function(err, db) {
        if (logger("db open"), err) return callback(err);
        var root = null === my.tar ? my.root : my.dir;
        makeDir(root, function(err, name) {
            return err ? callback(err) : void makeDir(name + db.databaseName + path.sep, function(err, name) {
                function go() {
                    return discriminator(db, name, my.query, metadata, parser, function(err) {
                        return logger("db close"), db.close(), err ? callback(err) : void (my.tar ? makeDir(my.root, function(e, name) {
                            err && error(err);
                            var dest;
                            my.stream ? (logger("send tar file to stream"), dest = my.stream) : (logger("make tar file at " + name + my.tar), 
                            dest = fs.createWriteStream(name + my.tar));
                            var packer = require("tar").Pack().on("error", callback).on("end", function() {
                                rmDir(root), callback(null);
                            });
                            require("fstream").Reader({
                                path: root + db.databaseName,
                                type: "Directory"
                            }).on("error", callback).pipe(packer).pipe(dest);
                        }) : callback(null));
                    }, my.collections);
                }
                return err ? callback(err) : void (my.metadata === !1 ? go() : (metadata = name + ".metadata" + path.sep, 
                makeDir(metadata, go)));
            });
        });
    });
}

function backup(options) {
    var opt = options || Object.create(null);
    if (!opt.uri) throw new Error("missing uri option");
    if (!opt.stream) {
        if (!opt.root) throw new Error("missing root option");
        if (fs.existsSync(opt.root) && !fs.statSync(opt.root).isDirectory()) throw new Error("root option is not a directory");
    }
    var my = {
        dir: path.join(__dirname, "dump", path.sep),
        uri: String(opt.uri),
        root: path.resolve(String(opt.root || "")) + path.sep,
        stream: opt.stream || null,
        parser: opt.parser || "bson",
        numCursors: ~~opt.numCursors,
        collections: Array.isArray(opt.collections) ? opt.collections : null,
        callback: "function" == typeof opt.callback ? opt.callback : null,
        tar: "string" == typeof opt.tar ? opt.tar : null,
        query: "object" == typeof opt.query ? opt.query : {},
        logger: "string" == typeof opt.logger ? path.resolve(opt.logger) : null,
        options: "object" == typeof opt.options ? opt.options : {},
        metadata: Boolean(opt.metadata)
    };
    return my.stream && (my.tar = !0), wrapper(my);
}

var systemRegex = /^system\./, fs = require("graceful-fs"), path = require("path"), BSON, logger, meta;

module.exports = backup;
